% !TeX spellcheck = sv_SE
\documentclass[a4paper, 12pt]{report}

\usepackage[swedish]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}

\usepackage{graphicx}

\DeclareMathOperator{\sign}{sign}

\theoremstyle{definition}
\newtheorem{thm}{Sats}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Korrolarium}
\newtheorem{defi}{Definition}[section]
\newtheorem{ex}{Exempel}[section]
\theoremstyle{remark}
\newtheorem*{rem}{Observation}

\newtheorem*{reas}{Orsak}

\newcommand{\bfbeta}{{\boldsymbol{\beta}}}
\renewcommand\qedsymbol{$\blacksquare$}

\newcommand{\sephyp}{\{ \mathbf{x} : f(\mathbf{x})=\mathbf{x}^\intercal \bfbeta + \beta_0=0\}}

\newcommand{\entsephyp}{\{ \mathbf{x} : f(\mathbf{x})=\mathbf{x}^\intercal \bfbeta + \beta_0=0,~y_if(\mathbf{x}_i)\geq0,~i=1,\dots,~N,~\|\bfbeta\|=1\}}
\title{Hilbertrum med Reproducerande Kärnor}
\author{Oscar Granlund}


\begin{document}
\maketitle

\begin{abstract}
	Testtesttesttesttesttest
\end{abstract}

\chapter{Stödvektormaskiner (SVM)}

\section{Klassificering med hjälp av separerande hyperplan}

INTRODUKTION OM VARFÖR KLASSIFICERING, EXEMPEL MED SPAM-FILTER

\begin{defi}
	Ett \textit{klassificeringsproblem} är ett problem var man utgående från en mängd observationspar (\textit{träningsdata}) $(\mathbf{x}_i,~y_i)$, $\mathbf{x}_i\in\mathbb{R}^p$, $y_i\in \{-1,~1\}$, $i=1,\dots,~N$, försöker hitta en regel $g: \mathbb{R}^p \longmapsto \{-1,~1\}$ sådan att $g(\mathbf{x}_i)=y_i$ för alla träningspar $(\mathbf{x}_i,~y_i)$.
\end{defi}

Inom statistiken och maskininlärningen finns många olika metoder för att försöka lösa klassificeringsproblem, till exempel med hjälp av regression eller någon sorts klusteralgoritm. I detta kapitel behandlas en metod där affina mängder med dimensionerna $p-1$ används för att definiera en regel som klassificerar \textit{observationerna} $\mathbf{x}_i$ i \textit{klasserna} $y_i\in\{-1,~1\}$ genom separering.

\begin{defi}
	Ett \textit{hyperplan} i ett vektorrum med dimensionen $p$ är ett underrum med dimensionen $p-1$; figur \ref{fig:separatinghyperplane} illustrerar ett separerande hyperplan för fallet $p=2$. Klassificeringsregeln $g$ för separerande hyperplan blir $g(\mathbf{x}_i)=\sign (\mathbf{x}_i^\intercal    \bfbeta + \beta_0)$ där mängden $\{\mathbf{x}: \mathbf{x}^\intercal \bfbeta + \beta_0=0\}$, med $\mathbf{x},~\bfbeta\in \mathbb{R}^p$ och $\|\bfbeta\|=1$, definierar ett hyperplan, eller en \textit{affin} mängd, parametriserat av $\boldsymbol\beta$ och $\beta_0$.
\end{defi}

\begin{thm}\label{thm:hyperplan}
	Ett hyperplan definierat som den affina mängden $L=\sephyp$ har följande egenskaper \cite{ESL}:
	\begin{enumerate}
		\item Den normaliserade normalvektorn $\widehat{\bfbeta}$ kan skrivas på formen
		\begin{equation*}
			\widehat{\bfbeta} = \frac{\bfbeta}{\|\bfbeta\|}.
		\end{equation*}
		\item $\mathbf{x}_0^\intercal \bfbeta = -\beta_0$ för alla $\mathbf{x}_0$ i $L$.
		\item Det signerade avståndet från en punkt $\mathbf{x}$ till hyperplanet $L$ ges av
		\begin{equation*}
		\begin{aligned}
			(\mathbf{x}-\mathbf{x}_0)^\intercal \widehat{\bfbeta} &= \frac{1}{\|\bfbeta\|}(\mathbf{x}^\intercal \bfbeta+\beta_0)\\
			&= \frac{1}{\|f^\prime(\mathbf{x})\|}f(\mathbf{x}).
		\end{aligned}
		\end{equation*}
	\end{enumerate}
\end{thm}
\begin{proof}
	\leavevmode
\begin{enumerate}
	\item Låt $\mathbf{x}_1$ och $\mathbf{x}_2$ vara två punkter i $L$. Då gäller att $f(\mathbf{x}_1)=f(\mathbf{x}_2)=0$ och
	\begin{align*}
		0 &= f(\mathbf{x}_1)-f(\mathbf{x}_2)\\
		&= \mathbf{x}_1^\intercal \bfbeta + \beta_0 - \mathbf{x}_2^ \intercal \bfbeta - \beta_0\\
		&= (\mathbf{x}_1-\mathbf{x}_2)^\intercal \bfbeta
	\end{align*}
	alltså uppfyller $\bfbeta$ kravet för normalvektorer och $\widehat{\bfbeta}:=\frac{\bfbeta}{\|\bfbeta\|}$ är den normaliserade normalvektorn till hyperplanet $L$. \hfill\qedsymbol
	\item Låt $\mathbf{x}_0$ vara en punkt i $L$. Då gäller att $f(\mathbf{x}_0)=\mathbf{x}_0^\intercal \bfbeta + \beta_0 = 0$ alltså är $\mathbf{x}^\intercal \bfbeta = - \beta_0$.\hfill \qedsymbol
	\item Låt $\mathbf{x}_0$ vara en punkt i hyperplanet $L$. Då är avståndet från hyperplanet till punkten $\mathbf{x}$ lika med längden av projektionen av vektorn $(\mathbf{x}-\mathbf{x}_0)$ på hyperplanets normal, $\beta$. Vi får alltså att
	\begin{align*}
		\operatorname{d^\pm} ( \mathbf{x}, L ) &= \operatorname{comp_{\bfbeta}} ( \mathbf{x} - \mathbf{x}_0 )
		=\underline{\underline{ (\mathbf{x} - \mathbf{x}_0)^\intercal \widehat{\bfbeta} }}\\
		&= \frac{1}{\|\bfbeta\|}(\mathbf{x}^\intercal\bfbeta - \mathbf{x}_0^\intercal\bfbeta)=\underline{\underline{\frac{1}{\|\bfbeta\|}(\mathbf{x}^\intercal\bfbeta + \bfbeta_0)}}
	\end{align*}
	och om man noterar att $f(\mathbf{x})=\mathbf{x}^\intercal\bfbeta+\beta_0$ och $f^\prime(\mathbf{x})=\bfbeta$ så fås även att
	\begin{equation*}
		\frac{1}{\|\bfbeta\|}(\mathbf{x}^\intercal\bfbeta + \bfbeta_0)=\frac{1}{\|f^\prime(\mathbf{x})\|}f(\mathbf{x}).
	\end{equation*}
	\qedhere
\end{enumerate}
\end{proof}

\begin{rem}
	Definitionen för hyperplanet $L=\{ \mathbf{x} : f(\mathbf{x})=\mathbf{x}^\intercal \bfbeta + \beta_0=0\}$ är inte entydig.
\end{rem}
\begin{reas}
	Betrakta hyperplanen $L_1 = \sephyp$ och $L_2 = \{\mathbf{x}: g(\mathbf{x})=\mathbf{x}^\intercal(-1\cdot\bfbeta) + (-1 \cdot \beta_0)\}$. Eftersom att $g(\mathbf{x}) = -f(\mathbf{x})$ så gäller att om $\mathbf{x}$ tillhör $L_1$ så tillhör $\mathbf{x}$ även $L_2$.
	Betrakta vidare $L_3= \{\mathbf{x}: h(\mathbf{x})=\frac{\mathbf{x}^\intercal\bfbeta}{\|\bfbeta\|} + \frac{\beta_0}{\|\bfbeta\|}\}=0$. Om $\mathbf{x}$ då tillhör $L_1$ så tillhör $\mathbf{x}$ även $L_3$ eftersom att $h(\mathbf{x}) = \frac{f(\mathbf{x})}{\|\bfbeta\|}=0$. Notera även att $\|\bfbeta\|$ kunde ha varit vilket reellt tal $\alpha$ som helst.
\end{reas}

\begin{rem}
	För att få entydiga hyperplan för klassificering kan man lägga till villkor. Om man kräver att $\|\bfbeta\|=1$ och $y_i(\mathbf{x}_i^\intercal\bfbeta + \beta_0)\geq0$ för alla $i=1,\dots,~N$, där $y_i$ är klasserna i klassificeringsproblemet, så får man en entydig definition av hyperplanet där vektorn $\bfbeta$ ''pekar mot`` klassen där $y_i=1$ och $\beta_0$ anger det signerade avståndet (med avseende på vart $\bfbeta$ pekar) från origo till hyperplanet.
\end{rem}
\begin{reas}
	De extra villkoren gör att man inte längre kan göra manipulationerna som påvisade icke-entydigheten. Om man sätter $\mathbf{x}=\bar{0}$ så får man med hjälp av sats \ref{thm:hyperplan} att avståndet från origo till planet är lika med $\frac{1}{\|\bfbeta\|}(\mathbf{x}^\intercal\bfbeta+\beta_0)=\beta_0$.
\end{reas}

\begin{figure}
\centering
\includegraphics[width=0.8\linewidth]{example-image-a}
\caption{\label{fig:separatinghyperplane}20 datapunkter med ett separerande hyperplan (linje) där klassen $y=1$ har färgats blå och klassen $y=-1$ har färgats orange.}
\end{figure}

\begin{defi}
	Ett klassificeringsproblem kallas \textit{separabelt} om det existerar ett hyperplan $L=\sephyp$ som separerar mängderna.
\end{defi}

\begin{thm}
	För ett hyperplan $L=\entsephyp$ som separerar två klasser gäller att
	\begin{equation}
		y_i(\mathbf{x}_i^\intercal \bfbeta + \beta_0) > 0
	\end{equation}
	för alla $i = 1, \dots,~N$.
\end{thm}
\begin{proof}
	Ifall ett klassificeringsproblem är separabelt så ligger alla observationer $y_i$ på rätt sida av hyperplanet definierat genom $\mathbf{x}^\intercal \bfbeta + \beta_0$; eller så ligger alla observationer på fel sida av hyperplanet. Vilket betyder att ifall $y_i=1$ så är $\mathbf{x}_i^\intercal \bfbeta + \beta_0 > 0$ och om $y_i=-1$ så är $\mathbf{x}_i^\intercal \bfbeta + \beta_0 < 0$. Detta betyder att $y_i(\mathbf{x}_i^\intercal \bfbeta + \beta_0) > 0$. Ifall $\mathbf{x}_i^\intercal \bfbeta + \beta_0 = 0$ är problemet inte separabelt.
\end{proof}

\begin{ex}
	Låt träningsdataparen vara $(\left[2,~2\right]^\intercal,~1),~(\left[1,~2\right]^\intercal,-1)$. Då är $$L_1=\{\mathbf{x}\in\mathbb{R}^2: \mathbf{x}^\intercal\begin{bmatrix}
	1\\
	0
	\end{bmatrix} + 1.5=0\}$$ och $$L_2=\{\mathbf{x}\in\mathbb{R}^2: \mathbf{x}^\intercal\begin{bmatrix}
	\sqrt{2}\\
	\sqrt{2}
	\end{bmatrix} + 1.5=0\}$$ två separerande hyperplan (linjer i detta fall).
\end{ex}
\begin{proof}
	För $L_1$: 
\end{proof}
%%%%	KANSKE REFERENS TILL VAPNIK 1996



\bibliographystyle{plain}
\bibliography{bibliografi}
\end{document}          
